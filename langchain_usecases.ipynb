{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e1d087",
   "metadata": {},
   "source": [
    "[LangChain Cookbook Part2](https://github.com/ea-datascience/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa92741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Initialize the OpenAI API\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "open_ai_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "google_cse_id = os.environ[\"GOOGLE_CSE_ID\"]\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a01cb",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "\n",
    "1. Summarization\n",
    "2. Question and Answering over documents\n",
    "3. Extraction\n",
    "4. Evaluation\n",
    "5. Querying Tabular Data\n",
    "6. Code understanding\n",
    "7. Interacting with APIs\n",
    "8. Chatbots\n",
    "9. Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d3872",
   "metadata": {},
   "source": [
    "### 1. SUMMARIZATION\n",
    "\n",
    "Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1549aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Note that what is the default model 'text-davinci-003'\n",
    "llm = OpenAI(temperature = 0, model_name = 'text-davinci-003', openai_api_key = open_ai_key)\n",
    "\n",
    "# Create our template\n",
    "template = \"\"\"\n",
    "% INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand.\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# Create a LangChain prompt template that we can insert values to later\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"text\"],\n",
    "    template = template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358acafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusing_text = \"\"\"\n",
    "For the next 130 years, debate raged.\n",
    "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
    "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
    "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5410070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Prompt Begin -------\n",
      "\n",
      "% INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "Respond in a manner that a 5 year old would understand.\n",
      "\n",
      "%TEXT:\n",
      "\n",
      "For the next 130 years, debate raged.\n",
      "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
      "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
      "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
      "\n",
      "\n",
      "------- Prompt End -------\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Prompt Begin -------\")\n",
    "\n",
    "final_prompt = prompt.format(text = confusing_text)\n",
    "print(final_prompt)\n",
    "\n",
    "print(\"------- Prompt End -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3785067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 130 years, people argued about what Prototaxites was. Some thought it was a lichen, some thought it was a fungus, and some thought it was a tree. But no one could agree because when you looked closely, it looked like a lot of different things. It was also very big, so people were surprised that it could be a lichen.\n"
     ]
    }
   ],
   "source": [
    "output = llm(final_prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220b0b2",
   "metadata": {},
   "source": [
    "## 1.2 SUMMARIES OF LONGER TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3ec66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5aee590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we started Y Combinator we came up with the\n",
      "phrase that became our motto: Make something people want.  We've\n",
      "learned a lot since then, but if I were choosing now that's still\n",
      "the one I'd pick.Another thing w\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/PaulGrahamEssays/good.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Previewing the first 300 characters\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a8821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3970 tokens in your file\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print(f\"There are {num_tokens} tokens in your file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee6355",
   "metadata": {},
   "source": [
    "Let us chunck the text in pieces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f643ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have 4 docs instead of 1 piece of text\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size = 5000, chunk_overlap = 350)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print(f\"You now have {len(docs)} docs instead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383fb4c",
   "metadata": {},
   "source": [
    "We are going to load a chain to run a map reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc90d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm = llm, chain_type = \"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502535b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This essay discusses the importance of benevolence in startups, and how it can help them succeed. It explains how benevolence can improve morale, make people want to help, and help startups be decisive. It also explains how being benevolent and committed can make startups hard to kill, and how it can attract investors, customers, other companies, and potential employees. Finally, it looks at how markets have evolved to value potential dividends and potential earnings, and how users dislike their new operating system.\n"
     ]
    }
   ],
   "source": [
    "output = chain.run(docs)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce345307",
   "metadata": {},
   "source": [
    "## 2. QUESTION AND ANSWERING USING DOCUMENTS AS CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1f1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple example\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)\n",
    "\n",
    "context = \"\"\"\n",
    "Rachel is 30 years old\n",
    "Bob is 45 years old\n",
    "Kevin is 65 years old\n",
    "\"\"\"\n",
    "\n",
    "question = \"Whos is under 40 years old?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60ffca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel is the only one under 40 years old.\n"
     ]
    }
   ],
   "source": [
    "output = llm(context + question)\n",
    "print(output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4e139",
   "metadata": {},
   "source": [
    "### Using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12322e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "# The vector store we will be using, there are several, like Pinecone\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# The LangChain component we'll use to get the documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# The easy document loader for text\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# The embedding engine that wil convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92c7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 16697 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"data/PaulGrahamEssays/good.txt\")\n",
    "doc = loader.load()\n",
    "print(f\"You have {len(doc)} document\")\n",
    "print(f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda2c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 3000, chunk_overlap = 400)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcff41b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 7 documents that have an average. of 2,684 characters\n"
     ]
    }
   ],
   "source": [
    "# Get the average number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print(f\"Now you have {len(docs)} documents that have an average. of {num_total_characters/len(docs):,.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b7e8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = open_ai_key)\n",
    "\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad3abba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your retrieval engine\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm = llm, chain_type = \"stuff\", retriever = docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a4e4d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The author describes good work as work that makes the world better and helps people.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to ask our question\n",
    "query = \"What does the author describe as good work?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee37fb",
   "metadata": {},
   "source": [
    "## 3. Extraction\n",
    "\n",
    "This is the process of parsing data from a piece of text. This is commonly used with output parsing in order to structure our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec07240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "chat_model = ChatOpenAI(temperature = 0, model = 'gpt-3.5-turbo', openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24c6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us run a simple extraction\n",
    "\n",
    "instructions = \"\"\"\n",
    "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them \n",
    "Return the fruit name and emojis in a python dictionary\n",
    "\"\"\"\n",
    "\n",
    "fruit_names = \"\"\"\n",
    "Apple, Pear, this is a kiwi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bd424f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Apple\": \"🍎\", \"Pear\": \"🍐\", \"Kiwi\": \"🥝\"}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Make your prompt which combines the instructions w/ fruit names\n",
    "prompt = (instructions + fruit_names)\n",
    "\n",
    "\n",
    "# Cal the LLM\n",
    "output = chat_model([HumanMessage(content = prompt)])\n",
    "\n",
    "print(output.content)\n",
    "print(type(output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ffbfe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': '🍎', 'Pear': '🍐', 'Kiwi': '🥝'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output_dict = eval(output.content)\n",
    "\n",
    "print(output_dict)\n",
    "print(type(output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b4fa6",
   "metadata": {},
   "source": [
    "### Using LangChain Response Schema\n",
    "\n",
    "This will do two things:\n",
    "\n",
    "1. Autogenerate the prompt with bonafide format instructions. This is great because I don't need to worry about the prompt engineering side.\n",
    "2. Read the output from the LLM and turn it into a proper python object for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78be7945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# the schema we want out\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name = \"artist\", description = \"The name of the musical artist\"),\n",
    "    ResponseSchema(name = \"song\", description = \"The name of the song that the artist plays\")\n",
    "]\n",
    "\n",
    "# The parser that will look for the LLM output in my schema and return it back to me\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# The format instructions that LangChain makes. Let's look at them\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b44f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a command from the user, extract the artist and song names \n",
      "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n",
      "I really like So Young by Portugal. The Man\n"
     ]
    }
   ],
   "source": [
    "# The prompt template that brings it all together\n",
    "# This is a different prompt template than before, because we are using a Chat Model\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages = [\n",
    "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
    "                                                    {format_instructions}\\n{user_prompt}\")\n",
    "    ],\n",
    "    input_variables = [\"user_prompt\"],\n",
    "    partial_variables = {\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "fruit_query = prompt.format_prompt(user_prompt = \"I really like So Young by Portugal. The Man\")\n",
    "print(fruit_query.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "655fbaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': 'Portugal. The Man', 'song': 'So Young'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "fruit_output = chat_model(fruit_query.to_messages())\n",
    "output = output_parser.parse(fruit_output.content)\n",
    "\n",
    "print(output)\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083bde8",
   "metadata": {},
   "source": [
    "## 4. EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0996",
   "metadata": {},
   "source": [
    "Evaluating the process of doing quality checks on the output of your applications.\n",
    "This runs quality checks on your summarizations or Q&A pipelines, check the output of your summarizations pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e02cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Model and doc loader\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Eval \n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03752e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 74663 characters in that document\n"
     ]
    }
   ],
   "source": [
    "# A long essay\n",
    "\n",
    "loader = TextLoader(\"data/PaulGrahamEssays/worked.txt\")\n",
    "doc = loader.load()\n",
    "\n",
    "print(f\"You have {len(doc)} document\")\n",
    "print(f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d26d50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 124 documents that have an average of 965 characters\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 400)\n",
    "docs = text_splitter.split_documents(doc)\n",
    "\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print(f\"Now you have {len(docs)} documents that have an average of {num_total_characters/ len(docs):,.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b8cd074",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key = open_ai_key)\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04630aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm = llm, chain_type = \"stuff\", retriever = docsearch.as_retriever(), input_key = \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddaf99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = [\n",
    "    {'question' : \"Which company sold the microcomputer kit that his friend built himself?\", 'answer' : 'Healthkit'},\n",
    "    {'question' : \"What was the small city he talked about in the city that is the financial capital of USA?\", 'answer' : 'Yorkville, NY'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d9d26",
   "metadata": {},
   "source": [
    "The second question is intentionally wrong, we want an error to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8de5335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which company sold the microcomputer kit that his friend built himself?',\n",
       "  'answer': 'Healthkit',\n",
       "  'result': ' Heathkit.'},\n",
       " {'question': 'What was the small city he talked about in the city that is the financial capital of USA?',\n",
       "  'answer': 'Yorkville, NY',\n",
       "  'result': ' New York City'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = chain.apply(question_answers)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e04b57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can ask the chain to grade itself\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(question_answers,\n",
    "                                    predictions,\n",
    "                                    question_key = \"question\",\n",
    "                                    prediction_key = \"result\",\n",
    "                                    answer_key = \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96bc82e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' CORRECT'}, {'text': ' INCORRECT'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f872c1",
   "metadata": {},
   "source": [
    "## 5. QUERYING TABULAR DATA\n",
    "\n",
    "Leverage LLMs to do data analysis and get information out of the DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f297484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
    "\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)\n",
    "\n",
    "sqlite_db_path = 'data/San_Francisco_Trees.db'\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c50136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many Species of trees are there in San Francisco?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT COUNT(DISTINCT \"qSpecies\") FROM \"SFTrees\";\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(578,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m There are 578 Species of trees in San Francisco.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' There are 578 Species of trees in San Francisco.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain(llm = llm, database = db, verbose = True)\n",
    "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b396b6d",
   "metadata": {},
   "source": [
    "This is awesome, there are a few steps at play here:\n",
    "\n",
    "1. Find which table to use\n",
    "2. Find which column to use\n",
    "3. Construct the correct sql query\n",
    "4. Execute that query\n",
    "5. Get the result\n",
    "6. Return a natural language response back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ee91260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
    "\n",
    "# Read the SQL query into a Pandas Dataframe\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d629ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e85ff",
   "metadata": {},
   "source": [
    "## 6. CODE UNDERSTANDING \n",
    "\n",
    "This can do Co-Pilot like things, like answer questions about libraries and generate new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb7373c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Vector Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Model and chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Text splitters \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-3.5-turbo', openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f077021",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special = (), openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725684c",
   "metadata": {},
   "source": [
    "Let us parse some python code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44555bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data/thefuzz'\n",
    "docs = []\n",
    "\n",
    "# Go throgh each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try:\n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding = 'utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c91d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 175 documents \n",
      "\n",
      "------ Start document -------\n",
      "import unittest\n",
      "import re\n",
      "import pycodestyle\n",
      "\n",
      "from thefuzz import fuzz\n",
      "from thefuzz import process\n",
      "from thefuzz import utils\n",
      "from thefuzz.string_processing import StringProcessor\n",
      "\n",
      "\n",
      "class StringProcessingTest(unittest.TestCase):\n",
      "    def test_replace_non_letters_non_numbers_with_whitespace(self):\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"You have {len(docs)} documents \\n\")\n",
    "print(f\"------ Start document -------\")\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0a0a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e5edc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the retriever ready\n",
    "qa = RetrievalQA.from_chain_type(llm = llm, chain_type=\"stuff\", retriever = docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbc8adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What function do I use if I want to find the most similar item in a list items?\"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8926adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `process.extractOne()` function from thefuzz library to find the most similar item in a list of items.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5afd3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example usage of the `process.extractOne()` function:\n",
      "\n",
      "```\n",
      "from fuzzywuzzy import process\n",
      "\n",
      "query = \"chicago cubs vs new york mets\"\n",
      "choices = [\n",
      "    \"new york mets vs chicago cubs\",\n",
      "    \"chicago cubs at new york mets\",\n",
      "    \"atlanta braves vs pittsbugh pirates\",\n",
      "    \"new york yankees vs boston red sox\"\n",
      "]\n",
      "\n",
      "best_match = process.extractOne(query, choices)\n",
      "\n",
      "print(best_match)\n",
      "```\n",
      "\n",
      "This will output the best match for the `query` within the `choices`.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you write the code to use the process.extractOne() function? Only respond with code. No other text or explanation\"\n",
    "output = qa.run(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f225a0",
   "metadata": {},
   "source": [
    "## 7. INTERACTING WITH APIS\n",
    "\n",
    "How to let your system, intereact with APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cc4d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc2509b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_docs = \"\"\"\"\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Ex: italy, france\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Used to find information about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "    \n",
    "Woo! This is my documentation\n",
    "\"\"\"\n",
    "\n",
    "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9f5bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/cuba\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Cuba\",\"official\":\"Republic of Cuba\",\"nativeName\":{\"spa\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"}}},\"tld\":[\".cu\"],\"cca2\":\"CU\",\"ccn3\":\"192\",\"cca3\":\"CUB\",\"cioc\":\"CUB\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"CUC\":{\"name\":\"Cuban convertible peso\",\"symbol\":\"$\"},\"CUP\":{\"name\":\"Cuban peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"3\"]},\"capital\":[\"Havana\"],\"altSpellings\":[\"CU\",\"Republic of Cuba\",\"República de Cuba\"],\"region\":\"Americas\",\"subregion\":\"Caribbean\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"جمهورية كوبا\",\"common\":\"كوبا\"},\"bre\":{\"official\":\"Republik Kuba\",\"common\":\"Kuba\"},\"ces\":{\"official\":\"Kubánská republika\",\"common\":\"Kuba\"},\"cym\":{\"official\":\"Gweriniaeth Ciwba\",\"common\":\"Ciwba\"},\"deu\":{\"official\":\"Republik Kuba\",\"common\":\"Kuba\"},\"est\":{\"official\":\"Kuuba Vabariik\",\"common\":\"Kuuba\"},\"fin\":{\"official\":\"Kuuban tasavalta\",\"common\":\"Kuuba\"},\"fra\":{\"official\":\"République de Cuba\",\"common\":\"Cuba\"},\"hrv\":{\"official\":\"Republika Kuba\",\"common\":\"Kuba\"},\"hun\":{\"official\":\"Kubai Köztársaság\",\"common\":\"Kuba\"},\"ita\":{\"official\":\"Repubblica di Cuba\",\"common\":\"Cuba\"},\"jpn\":{\"official\":\"キューバ共和国\",\"common\":\"キューバ\"},\"kor\":{\"official\":\"쿠바 공화국\",\"common\":\"쿠바\"},\"nld\":{\"official\":\"Republiek Cuba\",\"common\":\"Cuba\"},\"per\":{\"official\":\"جمهوری کوبا\",\"common\":\"کوبا\"},\"pol\":{\"official\":\"Republika Kuby\",\"common\":\"Kuba\"},\"por\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"},\"rus\":{\"official\":\"Республика Куба\",\"common\":\"Куба\"},\"slk\":{\"official\":\"Kubánska republika\",\"common\":\"Kuba\"},\"spa\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"},\"srp\":{\"official\":\"Република Куба\",\"common\":\"Куба\"},\"swe\":{\"official\":\"Republiken Kuba\",\"common\":\"Kuba\"},\"tur\":{\"official\":\"Küba Cumhuriyeti\",\"common\":\"Küba\"},\"urd\":{\"official\":\"جمہوریہ کیوبا\",\"common\":\"کیوبا\"},\"zho\":{\"official\":\"古巴共和国\",\"common\":\"古巴\"}},\"latlng\":[21.5,-80.0],\"landlocked\":false,\"area\":109884.0,\"demonyms\":{\"eng\":{\"f\":\"Cuban\",\"m\":\"Cuban\"},\"fra\":{\"f\":\"Cubaine\",\"m\":\"Cubain\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDFA\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/1dDw1QfZspfMUTm99\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/307833\"},\"population\":11326616,\"fifa\":\"CUB\",\"car\":{\"signs\":[\"C\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"North America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/cu.png\",\"svg\":\"https://flagcdn.com/cu.svg\",\"alt\":\"The flag of Cuba is composed of five equal horizontal bands of blue alternating with white and a red equilateral triangle superimposed on the hoist side of the field. The triangle has its base on the hoist end, spans about two-fifth the width of the field and bears a white five-pointed star at its center.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/cu.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/cu.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[23.12,-82.35]},\"postalCode\":{\"format\":\"CP #####\",\"regex\":\"^(?:CP)*(\\\\d{5})$\"}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Cuba is a country located in the Americas region of the Caribbean. Its official language is Spanish and its currency is the Cuban convertible peso (CUC) and the Cuban peso (CUP). Its capital is Havana and its population is 11,326,616.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run(\"Can you tell me information about Cuba?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "befadd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/CUC\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Cuba\",\"official\":\"Republic of Cuba\",\"nativeName\":{\"spa\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"}}},\"tld\":[\".cu\"],\"cca2\":\"CU\",\"ccn3\":\"192\",\"cca3\":\"CUB\",\"cioc\":\"CUB\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"CUC\":{\"name\":\"Cuban convertible peso\",\"symbol\":\"$\"},\"CUP\":{\"name\":\"Cuban peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"3\"]},\"capital\":[\"Havana\"],\"altSpellings\":[\"CU\",\"Republic of Cuba\",\"República de Cuba\"],\"region\":\"Americas\",\"subregion\":\"Caribbean\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"جمهورية كوبا\",\"common\":\"كوبا\"},\"bre\":{\"official\":\"Republik Kuba\",\"common\":\"Kuba\"},\"ces\":{\"official\":\"Kubánská republika\",\"common\":\"Kuba\"},\"cym\":{\"official\":\"Gweriniaeth Ciwba\",\"common\":\"Ciwba\"},\"deu\":{\"official\":\"Republik Kuba\",\"common\":\"Kuba\"},\"est\":{\"official\":\"Kuuba Vabariik\",\"common\":\"Kuuba\"},\"fin\":{\"official\":\"Kuuban tasavalta\",\"common\":\"Kuuba\"},\"fra\":{\"official\":\"République de Cuba\",\"common\":\"Cuba\"},\"hrv\":{\"official\":\"Republika Kuba\",\"common\":\"Kuba\"},\"hun\":{\"official\":\"Kubai Köztársaság\",\"common\":\"Kuba\"},\"ita\":{\"official\":\"Repubblica di Cuba\",\"common\":\"Cuba\"},\"jpn\":{\"official\":\"キューバ共和国\",\"common\":\"キューバ\"},\"kor\":{\"official\":\"쿠바 공화국\",\"common\":\"쿠바\"},\"nld\":{\"official\":\"Republiek Cuba\",\"common\":\"Cuba\"},\"per\":{\"official\":\"جمهوری کوبا\",\"common\":\"کوبا\"},\"pol\":{\"official\":\"Republika Kuby\",\"common\":\"Kuba\"},\"por\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"},\"rus\":{\"official\":\"Республика Куба\",\"common\":\"Куба\"},\"slk\":{\"official\":\"Kubánska republika\",\"common\":\"Kuba\"},\"spa\":{\"official\":\"República de Cuba\",\"common\":\"Cuba\"},\"srp\":{\"official\":\"Република Куба\",\"common\":\"Куба\"},\"swe\":{\"official\":\"Republiken Kuba\",\"common\":\"Kuba\"},\"tur\":{\"official\":\"Küba Cumhuriyeti\",\"common\":\"Küba\"},\"urd\":{\"official\":\"جمہوریہ کیوبا\",\"common\":\"کیوبا\"},\"zho\":{\"official\":\"古巴共和国\",\"common\":\"古巴\"}},\"latlng\":[21.5,-80.0],\"landlocked\":false,\"area\":109884.0,\"demonyms\":{\"eng\":{\"f\":\"Cuban\",\"m\":\"Cuban\"},\"fra\":{\"f\":\"Cubaine\",\"m\":\"Cubain\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDFA\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/1dDw1QfZspfMUTm99\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/307833\"},\"population\":11326616,\"fifa\":\"CUB\",\"car\":{\"signs\":[\"C\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"North America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/cu.png\",\"svg\":\"https://flagcdn.com/cu.svg\",\"alt\":\"The flag of Cuba is composed of five equal horizontal bands of blue alternating with white and a red equilateral triangle superimposed on the hoist side of the field. The triangle has its base on the hoist end, spans about two-fifth the width of the field and bears a white five-pointed star at its center.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/cu.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/cu.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[23.12,-82.35]},\"postalCode\":{\"format\":\"CP #####\",\"regex\":\"^(?:CP)*(\\\\d{5})$\"}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The currency of Cuba is the Cuban convertible peso (CUC) and the Cuban peso (CUP). The symbol for the Cuban convertible peso is $.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run(\"Give me some information about the currency CUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a2f9c",
   "metadata": {},
   "source": [
    "## 8. CHATBOTS\n",
    "\n",
    "Have a real time interaction with a user, provide an approachable UI for users to ask natural language questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91e68fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "# Chat specific components\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83443261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us customize the context we are given to the chatbot\n",
    "\n",
    "template = \"\"\"\n",
    "You are a chatbot that is unhelpful.\n",
    "Your goal is to not helpt the user but only make jokes.\n",
    "Take what the user is saying and make a joke out of it.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"chat_history\", \"human_input\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efb8c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm = OpenAI(openai_api_key = open_ai_key),\n",
    "    prompt = prompt,\n",
    "    verbose = True,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "899103fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not helpt the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it.\n",
      "\n",
      "\n",
      "Human: Is a pear a fruit or a vegetable\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A pear is fruit of the wise - they know when to stay out of the vegetable aisle!'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"Is a pear a fruit or a vegetable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f34e8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not helpt the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it.\n",
      "\n",
      "Human: Is a pear a fruit or a vegetable\n",
      "AI: A pear is fruit of the wise - they know when to stay out of the vegetable aisle!\n",
      "Human: What was one of the fruits I first asked you about?\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An apple, of course! After all, an apple a day keeps the doctor away.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"What was one of the fruits I first asked you about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b808a",
   "metadata": {},
   "source": [
    "## 9. AGENTS\n",
    "\n",
    "Programs that run autonomously without the need for human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ad14be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# Agent imports\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper, TextRequestsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e145c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0, openai_api_key = open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e582437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "requests = TextRequestsWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fcdc477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func = search.run, \n",
    "        description = \"useful for when you need to search google to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Requests\",\n",
    "        func = requests.get, \n",
    "        description = \"Useful for when you need to request an URL\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4524df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent = \"zero-shot-react-description\", verbose = True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83fa4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the capital of Cuba is.\n",
      "Action: Search\n",
      "Action Input: \"capital of Cuba\"\u001b[0m\u001b[36;1m\u001b[1;3mHavana is the largest city and capital; other major cities include Santiago de Cuba and Camagüey. The official area of the Republic of Cuba is 109,884 km2 ... Apr 25, 2023 ... Cuba is a multicultural, largely urban nation, although it has only one major city: Havana (La Habana), the capital and commercial hub of ... Havana is the capital and largest city of Cuba. The heart of the La Habana Province, Havana is the country's main port and commercial center. Havana, Spanish La Habana, city, capital, major port, and leading commercial centre of Cuba. It also constitutes one of Cuba's 15 provinces: Ciudad de la ... Apr 7, 2016 ... President Obama's recent trip to Cuba has highlighted both the ongoing tensions between Havana and Washington and the potential for an improved ... Havana is the capital city, a largest province, a major port, and a leading commercial centre of Cuba. The city has a population of 2.1 million inhabitants, ... Oct 17, 2011 ... Police closed the Havana offices of the Coral Capital Group Ltd last week and arrested chief executive Amado Fakhre, a Lebanese-born British ... Human Capital Index (HCI) (scale 0-1) - Cuba from The World Bank: Data. This facilitated U.S. penetration of the Cuban economy. Sugar estates and mining interests passed from Spanish and Cuban to U.S. hands, and it was U.S. capital, ... Gross capital formation (% of GDP) - Cuba from The World Bank: Data.\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Havana is the capital of Cuba.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Havana is the capital of Cuba.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent({\"input\": \"What is the capital of Cuba?\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "834a7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the number of employees of this company\n",
      "Action: Search\n",
      "Action Input: \"ACP IT Solutions GmbH employees\"\u001b[0m\u001b[36;1m\u001b[1;3mACP IT Solutions Company | 181 followers on LinkedIn. ACP IT Solutions is a division of All Copy Products, a firm with a deep heritage in Colorado and the ... ACP's revenue is $845.7 Million What is ACP's SIC code? ACP's SIC: 73,737 What is ACP's NAICS code? ACP's NAICS: ... ACP IT Solutions support modern, innovative companies in realizing their ideas and business ... Germany Companies With Less Than $1M in Revenue (Top 10K). ACP's revenue is $80.9 Million What is ACP's SIC code? ACP's SIC: 73,737 What is ACP's NAICS code? ACP's NAICS: ... Solutions Architect Sales · Co-Founder · Health and Public Sector · Working Student · Technical Account Manager Intern | Enterprise Services · System Sales Intern. Apr 9, 2023 ... Install and uncover ACP Advanced Circuit Pursuit AG's employee details in less than 30 secs. Sign-up for 6sense Revenue AI™ for Sales. To find ... Find company research, competitor information, contact details & financial data for ACP IT Solutions GmbH of Wien, Wien. ... Employees (this site):. ACP IT Solutions | 64 followers on LinkedIn. ACP IT Solutions (P)Ltd a company incorporated under the companies act, inherits its roots from Aryan Computers ... ACP IT Solutions Company | 181 (na) tagasubaybay sa LinkedIn. ACP IT Solutions is a division of All Copy Products, a firm with a deep heritage in Colorado ... A1 Telekom Austria AG. Sep 2011 - Apr 2015 3 years 8 months. Upper Austria. As System Engineer i ...\u001b[0m\u001b[32;1m\u001b[1;3m From the search results, it looks like ACP IT Solutions GmbH has around 64 employees.\n",
      "Final Answer: ACP IT Solutions GmbH has around 64 employees.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ACP IT Solutions GmbH has around 64 employees.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent({\"input\": \"How many employees ACP IT Solutions GmbH has?\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa42a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what this URL is about\n",
      "Action: Search\n",
      "Action Input: https://news.ycombinator.com/item?id=35963936\u001b[0m\u001b[36;1m\u001b[1;3m2 hours ago ... I've seen a cool project about forcing Llama to output valid JSON: https://twitter.com/GrantSlatton/status/1657559506069463040, ...\u001b[0m\u001b[32;1m\u001b[1;3m This URL is about a cool project about forcing Llama to output valid JSON\n",
      "Final Answer: This URL is about a cool project about forcing Llama to output valid JSON.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This URL is about a cool project about forcing Llama to output valid JSON.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent({\"input\": \"What is this url about: https://news.ycombinator.com/item?id=35963936\"})\n",
    "response['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfe97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
